---
layout: post
title:  逻辑斯蒂回归进行文本分类
date:   2018-07-08
categories: 自然语言处理 机器学习
---

本文介绍了简单的逻辑斯蒂回归文本分类。传统机器学习解决文本分类已经比较成熟，也很简单。可以说是会了不难，难了不会。逻辑斯底回归可以简单理解为将一个特征向量乘以一个矩阵，映射到另一个$C$维向量，矩阵的每一行是对应每一类的权重，矩阵的列数等于特征向量的维度。$C$维向量的每一维对应了$C$个类每一类的几率($logit$)，几率是一个样本是某类的概率除以不是此类的概率。再将几率向量经过一个$softmax$函数，得到了每一类的概率。取概率最大的类作为最终预测结果。本文重点不在逻辑斯底回归，而在于获取文本特征向量的数据预处理，和sklearn的基本机器学习流程。

本文特别感谢[基于sklearn的文本分类—逻辑回归](https://blog.csdn.net/laobai1015/article/details/80156506)，在此文基础上进行了一定修改，补充。

数据采用[THUCTC: 一个高效的中文文本分类工具包](http://thuctc.thunlp.org/#%E8%8E%B7%E5%8F%96%E9%93%BE%E6%8E%A5)中的`THUCNews.zip`。下载，解压，文件结构如下：
<img src="https://nlppupil.github.io/images/thunews.png" alt="BP" style="width:200px;height:380px;">