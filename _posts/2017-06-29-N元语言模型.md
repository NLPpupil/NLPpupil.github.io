---
layout: post
title:  "N元语言模型"
date:   2017-06-29 16:45:32
categories: 自然语言处理
---

#### **语言模型是干嘛的？**
语言模型可以计算任何句子的概率。例如，“I love you”的概率是多少？用数学语言表述，
$N$元语言模型($N$-gram model)根据一个词语的前$N-1$个词语，
来计算这个词语的概率。如果我们有了一个2元模型，“I love you”的概率就等于
$P(I)\times P(love|I)\times P(you|love)$（最后一段解释原因）。
2元模型用一个矩阵来表示，比如对于一个有10000个词的语料库，
这个语料库的2元模型就是一个$10000 \times 10000$的矩阵，
第$m$行第$n$列表示在第$m$个词语的条件下，第$n$个词语出现的概率，
即第$m$个词语后面跟着第$n$个词语的概率。如果我们知道了语言模型，
我们就可以像计算“I love you”那样，计算任何一个句子的概率。
#### **语言模型有什么用？**
语言模型在自然语言处理中占有重要的地位，在语音识别，机器翻译，
汉语自动分词和句法分析等都有应用。因为这些模型都会有噪声，
都会有几种不同的结果等着我们去选择，这时候就需要知道每种结果的概率，
来帮助我们选择。
为什么叫“语言模型”？因为这是统计学意义上的模型，又跟语言相关，所以叫语言模型。
统计模型指一系列分布，参数模型指一系列可用有限个参数表示的模型。
语言模型就是一种参数模型，它的参数是矩阵的所有cell。
#### **如何计算语言模型的参数？**
参数无法精确计算，只能大概估计。这里用的方法是极大似然估计。
对于某个语料库，极大似然估计的意思是，哪个语言模型（什么样的参数）
最有可能产生这个语料库呢？把这个问题分解成许多个小问题：
当$P(you|I)$是多少时（love和I可以换成别的所有的词），
最有可能产生这个语料库呢？自然而然我们会想到，统计语料库里一共有多少个I，
一共有多少个I love，然后做一下除法，就得到了我们想要的概率，
这个概率最有可能产生这个语料库。我们对这个语料库里所有的词对做相同的计数和除法，
就得到了我们想要的参数，也就得到了这个语料库的语言模型。
#### **那样计算概率的原因：马尔科夫假设**
然而，为什么I love you的概率可以通过
$ P(I)\times P(love|I)\times P(you|love) $
计算呢？其实这么算只是在某个假设下的近似计算，
这个假设就是一个词出现的概率只取决于它前$N-1$个词。
所以在二元模型下，I love you的概率可以那么算。
以此类推，三元模型下，I love you的概率就要这么算了：
$P(I) \times P(love|I) \times P(you| I,love)$。
<br>
<br>
<br>
参考资料：
《Speech and Language Processing》Jurafsky and Martin, Chapter 4
